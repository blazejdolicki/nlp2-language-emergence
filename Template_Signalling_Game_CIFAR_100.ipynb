{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Template_Signalling_Game--CIFAR-100.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFI90Pje3SmG"
      },
      "source": [
        "# Template for variable length Signalling Game\n",
        "\n",
        "This template is based on the [MNIST autoencoder tutorial](https://github.com/facebookresearch/EGG/blob/master/tutorials/EGG%20walkthrough%20with%20a%20MNIST%20autoencoder.ipynb) and [signal game implementation](https://github.com/facebookresearch/EGG/blob/master/egg/zoo/signal_game) provided by the [EGG library](https://github.com/facebookresearch/EGG).\n",
        "\n",
        "Some code is provided by Mathieu Bartels and Liselore Borel Rinkes at the UvA.\n",
        "\n",
        "Make sure you have a directory `SignalGame` in your Drive!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0_l9YwYJ9NL"
      },
      "source": [
        "# if you are running this notebook via Google Colab, you have to install EGG first\n",
        "!pip install git+https://github.com/facebookresearch/EGG.git\n",
        "\n",
        "# Setup connection to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd \"/content/drive/My Drive/SignalGame\"\n",
        "!mkdir -p 'models'\n",
        "!ls\n",
        "\n",
        "\n",
        "# also you'll need to change the runtime to GPU (Runtime -> Change runtime type -> Hardware Accelator -> GPU)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ps5ruebXSmtj"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "import scipy.spatial.distance as distance\n",
        "import scipy.stats\n",
        "import scipy\n",
        "import egg.core as core\n",
        "import egg.zoo as zoo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgJu9uxMLpj0"
      },
      "source": [
        "## Configuration\n",
        "Make sure to define some important configuration parameters in a convenient place, such as the number of images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngBTgCFSLpQw"
      },
      "source": [
        "import types\n",
        "import json\n",
        "\n",
        "# For convenience and reproducibility, we set some EGG-level command line arguments here\n",
        "opts = core.init(params=['--random_seed=7', # will initialize numpy, torch, and python RNGs\n",
        "                         '--lr=1e-3', # sets the learning rate for the selected optimizer \n",
        "                         '--batch_size=64',\n",
        "                         '--vocab_size=100',\n",
        "                         '--max_len=10',\n",
        "                         '--n_epochs=15',\n",
        "                         '--tensorboard',\n",
        "                         ]) \n",
        "\n",
        "# Other configurations that are not part of the above command line arguments we define separately. \n",
        "# Feel free to use a different format.\n",
        "_args_dict = {\n",
        "    \"architecture\" : {\n",
        "        \"embed_size\"      : 64,\n",
        "        \"hidden_sender\"   : 200,\n",
        "        \"hidden_receiver\" : 200,\n",
        "        \"cell_type\"       : 'gru',\n",
        "    },\n",
        "    \"game\" : {\n",
        "        \"num_imgs\"        : 2, # number of images the game is played with\n",
        "    },\n",
        "    \"training\" : {\n",
        "        \"temperature\"     : 1,\n",
        "        \"decay\"           : 0.9,\n",
        "        \"early_stop_accuracy\" : 0.97,\n",
        "    },\n",
        "}\n",
        "\n",
        "# A trick for having a hierarchical argument namespace from the above dict\n",
        "args = json.loads(json.dumps(_args_dict), object_hook=lambda item: types.SimpleNamespace(**item))\n",
        "\n",
        "print(\"Cell type of the agents:\", args.architecture.cell_type)\n",
        "\n",
        "# TODO: other configurations?\n",
        "raise NotImplementedError\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRHxMztINp6W"
      },
      "source": [
        "## Vision\n",
        "In this template we use the [CIFAR-100 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) for the images and use a fixed [pre-trained vision module](https://github.com/chenyaofo/CIFAR-pretrained-models/).\n",
        "The vision module will encode the images in the dataset before the agents get to see these.\n",
        "You can also choose to make the vision module part of the agents and update the parameters during playing the game (as in the MNIST tutorial)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROz8NxGJKC_W"
      },
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu  = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class Vision(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=100):\n",
        "        super(Vision, self).__init__()\n",
        "        self.inplanes = 16\n",
        "        self.conv1 = conv3x3(3, 16)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 16, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(64 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def classify(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        " \n",
        "# load pre-trained parameters\n",
        "num_classes = 100\n",
        "restnet_location = \"https://github.com/chenyaofo/CIFAR-pretrained-models/releases/download/resnet/cifar100-resnet56-2f147f26.pth\"\n",
        "vision = Vision(BasicBlock, [9, 9, 9], num_classes=num_classes).to(device)\n",
        "vision.load_state_dict(model_zoo.load_url(restnet_location))\n",
        "\n",
        "vision.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsjKgmmxKONz"
      },
      "source": [
        "## Data\n",
        "Implement a custom dataset to be used in the Signalling Game, building on top of a Dataset of your choice.\n",
        "*You could use the below code to use a featuriser for CIFAR-100 or implement your own!*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beE1Gto8bR72"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.RandomCrop(size=32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.5071, 0.4865, 0.4409],\n",
        "        std=[0.2009, 0.1984, 0.2023]\n",
        "    ),\n",
        "])\n",
        "\n",
        "cifar_train_set = datasets.CIFAR100('./data', train=True, download=True, transform=transform)\n",
        "\n",
        "cifar_test_set = datasets.CIFAR100('./data', train=False, transform=transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "By_MyH0_KM33"
      },
      "source": [
        "class SignalGameDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset, num_imgs, vision, classes=None):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __len__(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        raise NotImplementedError\n",
        "        return sender_imgs, target, receiver_imgs\n",
        "\n",
        "trainset = SignalGameDataset(cifar_train_set, args.game.num_imgs, vision)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, shuffle=True,\n",
        "                                          batch_size=opts.batch_size, num_workers=2)\n",
        "\n",
        "testset = SignalGameDataset(cifar_test_set, args.game.num_imgs, vision)\n",
        "testloader = torch.utils.data.DataLoader(testset, shuffle=False,\n",
        "                                         batch_size=opts.batch_size, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuIkT8KqK_fz"
      },
      "source": [
        "## Agent design\n",
        "We can use the Rnn Wrappers from EGG to implement a recurrent neural agent on top of your Sender and Receiver design. Here the Gumbel Softmax (GS) is used, but you can also use a [Reinforce Wrapper](https://github.com/facebookresearch/EGG/blob/master/egg/core/reinforce_wrappers.py).\n",
        "\n",
        "See [RnnSenderGS and RnnReceiverGS](https://github.com/facebookresearch/EGG/blob/master/egg/core/gs_wrappers.py) in the documentation for what happens under the hood."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6e77C67LH1U"
      },
      "source": [
        "### Sender"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av7icZpFN6Wj"
      },
      "source": [
        "class Sender(nn.Module):\r\n",
        "    def __init__(self, embed_size, num_imgs, hidden_sender):\r\n",
        "      super(Sender, self).__init__()\r\n",
        "      raise NotImplementedError\r\n",
        "        \r\n",
        "    def forward(self, imgs):\r\n",
        "      raise NotImplementedError\r\n",
        "\r\n",
        "sender = Sender(args.architecture.embed_size, args.game.num_imgs, args.architecture.hidden_sender)\r\n",
        "\r\n",
        "sender = core.RnnSenderGS(sender, opts.vocab_size, args.architecture.embed_size, args.architecture.hidden_sender, cell=args.architecture.cell_type,\r\n",
        "                        max_len=opts.max_len, temperature=args.training.temperature, straight_through=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oP1wc2jlLQky"
      },
      "source": [
        "### Receiver\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ro77SNUS1rN"
      },
      "source": [
        "class Receiver(nn.Module):\r\n",
        "    def __init__(self, hidden_size, embed_size):\r\n",
        "        super(Receiver, self).__init__()\r\n",
        "        raise NotImplementedError\r\n",
        "\r\n",
        "    def forward(self, hidden_state, imgs):\r\n",
        "        raise NotImplementedError\r\n",
        "\r\n",
        "receiver = Receiver(args.architecture.hidden_receiver, args.architecture.embed_size)\r\n",
        "\r\n",
        "receiver = core.RnnReceiverGS(receiver, opts.vocab_size, args.architecture.embed_size,\r\n",
        "                    args.architecture.hidden_receiver, cell=args.architecture.cell_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1gSNpSoLUe5"
      },
      "source": [
        "## Loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOr9uayQLSdj"
      },
      "source": [
        "def loss(_sender_input,  _message, _receiver_input, receiver_output, _labels):\n",
        "    raise NotImplementedError\n",
        "    return loss, {'acc': accuracy}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnCBbeyoLYPw"
      },
      "source": [
        "## Game setup and training\n",
        "Use `core.SenderReceiverRnnGS` for creating a variable message length game, set the optimizer and other options, and start training the agents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCVqdUY1TCKX"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8og00m4e7tF"
      },
      "source": [
        "model_prefix = f\"maxlen_{opts.max_len}\" # Example\r\n",
        "models_path = \"/content/drive/My Drive/SignalGame/models\" # location where we store trained models\r\n",
        "\r\n",
        "checkpointer = core.callbacks.CheckpointSaver(checkpoint_path=models_path, checkpoint_freq=0, prefix=model_prefix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xdWxbaBfMC5"
      },
      "source": [
        "game = core.SenderReceiverRnnGS(sender, receiver, loss)\r\n",
        "optimizer = torch.optim.Adam(game.parameters())\r\n",
        "\r\n",
        "callbacks = [core.TemperatureUpdater(agent=game.sender, decay=args.training.decay, minimum=0.1),\r\n",
        "             core.ConsoleLogger(as_json=True, print_train_loss=True),\r\n",
        "             core.TensorboardLogger(),\r\n",
        "             core.EarlyStopperAccuracy(args.training.early_stop_accuray),\r\n",
        "             checkpointer]\r\n",
        "\r\n",
        "trainer = core.Trainer(\r\n",
        "    game=game, optimizer=optimizer, train_data=trainloader,\r\n",
        "    validation_data=testloader, callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOJw2EBvfRk9"
      },
      "source": [
        "trainer.train(n_epochs=opts.n_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4rEbi4WThKw"
      },
      "source": [
        "%tensorboard --logdir ./runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_nA9yyIMt9r"
      },
      "source": [
        "## Evaluation of the emergent languages\n",
        "Next up, start analysing the languages and other behaviour you are interested in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kaY_pNf-UKr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}