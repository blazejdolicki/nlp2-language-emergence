{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.0 64-bit ('le-nlp2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "faf78f47fd8955034d4b777123a9000e41db7624cc754dae23eef5d5cda1ecdc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Image classification pressures in language emergence\n",
    "This repository contains PyTorch code for the short paper \"Visual concepts pressure in language emergence\". "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Installation\n",
    "Open Anaconda Prompt, create a new conda environment with Python 3.7 and activate it.\n",
    "```\n",
    "conda create -n le-nlp2 python=3.7\n",
    "conda activate le-nlp2\n",
    "```\n",
    "Install PyTorch and related libraries.\n",
    "```\n",
    "conda install pytorch=1.8.1 torchvision=0.9.1 torchaudio=0.8.1 cudatoolkit=10.2 -c pytorch\n",
    "```\n",
    "Install other packages.\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Install EGG library from Github repository (commit `ba7ba8f`).\n",
    "```\n",
    "pip install git+https://github.com/facebookresearch/EGG.git@ba7ba8f\n",
    "```\n",
    "\n",
    "If you wish to run this whole notebook, make sure that it runs in the newly created enviroment."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Code structure\n",
    "We divided our research code into multiple python files for better modularization. `main.py` is the most important file which is executed to perform experiments. It consists of the following steps: <br>\n",
    "\n",
    "1. Parsing arguments specified in command line such as the task (baseline or one of the pressures) and fixed parameters such as embedding size.\n",
    "\n",
    "2. Loading the `Vision` module (defined in `vision.py`) which is used to extract features from images.\n",
    "\n",
    "3. Creating the signaling game train and test datasets (`SignalGameDataset` defined in `dataset.py`)  based on Cifar100. `SignalGameDataset` reads Cifar100 images, extracts their features with the `Vision` and samples images used in the game. Sampling differs between tasks, as different labels are used.\n",
    "\n",
    "4. If `--eval_noise` argument was added in the command line, the Gaussian noise images dataset (`GaussianNoiseDataset` defined in `dataset.py`) is created. Noise images are created with the `_init_dataset()` method and afterwards the functionality is similar to `SignalGameDataset` - the images are passed through the `Vision` module and sampled for games.\n",
    "\n",
    "5. Initializing the Sender and the Receiver (defined in `sender.py` and `receiver.py`). When trying to reproduce results of Bouchacourt and Baroni, 2018, we tried multiple game types such as variable-length (`SenderReceiverRnnReinforce`) or single symbol (`SymbolGameReinforce`) game optimized with the Reinforce algorithm. However, in the paper results we only use a variable-length game optimized with Gumbel-softmax estimator (`SenderReceiverRnnGS`).\n",
    "\n",
    "6. Initializing the `BestEpochCheckpointSaver` callback. This is a custom callback, a subclass of `CheckpointSaver` implemented in the EGG library. It is implemented in `best_epoch_checkpoint.py`. As oppose to `CheckpointSaver`, `BestEpochCheckpointSaver` doesn't save the model checkpoint every n epochs, but only when the validation accuracy in the current epoch is the highest accuracy obtained so far. This is especially useful later in the pipeline.\n",
    "\n",
    "7. Setting the loss depending on the task. In this part, we were slightly constrained by the EGG library which requires passing the loss function as an argument of the `Game` object. Our obstacle was that for the pressure losses we wanted to use the `ic_loss_weight` parameter which is a weight determining how much the additional image classification loss contributes to the total loss. We wanted to the user to have the opportunity to specify this parameter from command line. Thus we created a wrapper class for the loss (`ImageClasLoss` and `TargetClasLoss` in `loss.py`) where this parameter is specified. Each wrapper implements a method `get_loss()` which calculates the pressure loss and utilizes the instance variable `ic_loss_weight`.\n",
    "\n",
    "8. Initializing the `Game` object, adding callbacks.\n",
    "\n",
    "9. Initializing the Trainer object and starting training.\n",
    "\n",
    "10. If `--eval_noise` argument was added in the command line, once training on Cifar100 is finished, the trained model is loaded and evaluated on the noise dataset.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Example usage\n",
    "It is possible to run 3 kinds of tasks: the `standard` signaling game with a single loss (baseline) and two tasks with additional visual pressures. You should run all experiments from the project root directory. It seems that the `tqdm` progress bar conflicts with printing in a notebook, so the outputs below look a bit messy. For better visual experience we recommend running these commands in the command line."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1. Baseline\n",
    "Run the following code to train and evaluate the baseline model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Log path: 28_03_2021_09_26_27_task_standard_seed_7\n",
      "Parameters specified in the command line:\n",
      "Image classification task: standard\n",
      "Game type:  SenderReceiverRnnGS\n",
      "Image classification loss weight:  1.0\n",
      "Number of images in the game:  2\n",
      "Same class probability:  0.0\n",
      "Evaluate on Gaussian noise images? False\n",
      "\n",
      "Cell type of the agents: gru\n",
      "Device: cuda\n",
      "Files already downloaded and verified\n",
      "Extract image features from train set\n",
      "Extract image features from test set Cifar100\n",
      "Start training\n",
      "{\"loss\": 0.31022676825523376, \"acc\": 0.8313999772071838, \"length\": 5.730979919433594, \"mode\": \"train\", \"epoch\": 1}\n",
      "{\"loss\": 0.20310336351394653, \"acc\": 0.9107999801635742, \"length\": 7.791299819946289, \"mode\": \"test\", \"epoch\": 1}\n",
      "{\"loss\": 0.10048744082450867, \"acc\": 0.9520000219345093, \"length\": 7.361539840698242, \"mode\": \"train\", \"epoch\": 2}\n",
      "{\"loss\": 0.08790679275989532, \"acc\": 0.961899995803833, \"length\": 8.959699630737305, \"mode\": \"test\", \"epoch\": 2}\n",
      "{\"loss\": 0.06602536141872406, \"acc\": 0.9698200225830078, \"length\": 9.187199592590332, \"mode\": \"train\", \"epoch\": 3}\n",
      "{\"loss\": 0.0782003402709961, \"acc\": 0.961899995803833, \"length\": 7.789000034332275, \"mode\": \"test\", \"epoch\": 3}\n",
      "{\"loss\": 0.05519534647464752, \"acc\": 0.9739400148391724, \"length\": 7.712679862976074, \"mode\": \"train\", \"epoch\": 4}\n",
      "{\"loss\": 0.045081187039613724, \"acc\": 0.9782000184059143, \"length\": 7.526599884033203, \"mode\": \"test\", \"epoch\": 4}\n",
      "2021-03-28 09:26:31.167953: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\n",
      "\n",
      "Extracting features in batches:   0%|          | 0/50 [00:00<?, ?it/s]\n",
      "Extracting features in batches:   2%|▏         | 1/50 [00:07<06:26,  7.88s/it]\n",
      "Extracting features in batches:   4%|▍         | 2/50 [00:08<02:43,  3.41s/it]\n",
      "Extracting features in batches:   6%|▌         | 3/50 [00:08<01:33,  1.99s/it]\n",
      "Extracting features in batches:   8%|▊         | 4/50 [00:08<01:01,  1.33s/it]\n",
      "Extracting features in batches:  10%|█         | 5/50 [00:09<00:43,  1.04it/s]\n",
      "Extracting features in batches:  12%|█▏        | 6/50 [00:09<00:32,  1.34it/s]\n",
      "Extracting features in batches:  14%|█▍        | 7/50 [00:09<00:25,  1.67it/s]\n",
      "Extracting features in batches:  16%|█▌        | 8/50 [00:10<00:21,  1.97it/s]\n",
      "Extracting features in batches:  18%|█▊        | 9/50 [00:10<00:18,  2.24it/s]\n",
      "Extracting features in batches:  20%|██        | 10/50 [00:10<00:16,  2.47it/s]\n",
      "Extracting features in batches:  22%|██▏       | 11/50 [00:10<00:14,  2.65it/s]\n",
      "Extracting features in batches:  24%|██▍       | 12/50 [00:11<00:14,  2.67it/s]\n",
      "Extracting features in batches:  26%|██▌       | 13/50 [00:11<00:12,  2.90it/s]\n",
      "Extracting features in batches:  28%|██▊       | 14/50 [00:11<00:12,  2.99it/s]\n",
      "Extracting features in batches:  30%|███       | 15/50 [00:12<00:11,  3.05it/s]\n",
      "Extracting features in batches:  32%|███▏      | 16/50 [00:12<00:10,  3.10it/s]\n",
      "Extracting features in batches:  34%|███▍      | 17/50 [00:12<00:10,  3.13it/s]\n",
      "Extracting features in batches:  36%|███▌      | 18/50 [00:13<00:10,  3.10it/s]\n",
      "Extracting features in batches:  38%|███▊      | 19/50 [00:13<00:09,  3.19it/s]\n",
      "Extracting features in batches:  40%|████      | 20/50 [00:13<00:09,  3.20it/s]\n",
      "Extracting features in batches:  42%|████▏     | 21/50 [00:14<00:09,  3.20it/s]\n",
      "Extracting features in batches:  44%|████▍     | 22/50 [00:14<00:08,  3.20it/s]\n",
      "Extracting features in batches:  46%|████▌     | 23/50 [00:14<00:08,  3.21it/s]\n",
      "Extracting features in batches:  48%|████▊     | 24/50 [00:15<00:08,  3.21it/s]\n",
      "Extracting features in batches:  50%|█████     | 25/50 [00:15<00:07,  3.21it/s]\n",
      "Extracting features in batches:  52%|█████▏    | 26/50 [00:15<00:07,  3.21it/s]\n",
      "Extracting features in batches:  54%|█████▍    | 27/50 [00:15<00:07,  3.21it/s]\n",
      "Extracting features in batches:  56%|█████▌    | 28/50 [00:16<00:06,  3.21it/s]\n",
      "Extracting features in batches:  58%|█████▊    | 29/50 [00:16<00:06,  3.21it/s]\n",
      "Extracting features in batches:  60%|██████    | 30/50 [00:16<00:06,  3.22it/s]\n",
      "Extracting features in batches:  62%|██████▏   | 31/50 [00:17<00:05,  3.21it/s]\n",
      "Extracting features in batches:  64%|██████▍   | 32/50 [00:17<00:05,  3.21it/s]\n",
      "Extracting features in batches:  66%|██████▌   | 33/50 [00:17<00:05,  3.21it/s]\n",
      "Extracting features in batches:  68%|██████▊   | 34/50 [00:18<00:04,  3.21it/s]\n",
      "Extracting features in batches:  70%|███████   | 35/50 [00:18<00:04,  3.21it/s]\n",
      "Extracting features in batches:  72%|███████▏  | 36/50 [00:18<00:04,  3.21it/s]\n",
      "Extracting features in batches:  74%|███████▍  | 37/50 [00:19<00:04,  3.21it/s]\n",
      "Extracting features in batches:  76%|███████▌  | 38/50 [00:19<00:03,  3.21it/s]\n",
      "Extracting features in batches:  78%|███████▊  | 39/50 [00:19<00:03,  3.21it/s]\n",
      "Extracting features in batches:  80%|████████  | 40/50 [00:20<00:03,  3.19it/s]\n",
      "Extracting features in batches:  82%|████████▏ | 41/50 [00:20<00:02,  3.22it/s]\n",
      "Extracting features in batches:  84%|████████▍ | 42/50 [00:20<00:02,  3.22it/s]\n",
      "Extracting features in batches:  86%|████████▌ | 43/50 [00:20<00:02,  3.22it/s]\n",
      "Extracting features in batches:  88%|████████▊ | 44/50 [00:21<00:01,  3.22it/s]\n",
      "Extracting features in batches:  90%|█████████ | 45/50 [00:21<00:01,  3.21it/s]\n",
      "Extracting features in batches:  92%|█████████▏| 46/50 [00:21<00:01,  3.22it/s]\n",
      "Extracting features in batches:  94%|█████████▍| 47/50 [00:22<00:00,  3.21it/s]\n",
      "Extracting features in batches:  96%|█████████▌| 48/50 [00:22<00:00,  3.21it/s]\n",
      "Extracting features in batches:  98%|█████████▊| 49/50 [00:22<00:00,  3.21it/s]\n",
      "Extracting features in batches: 100%|██████████| 50/50 [00:23<00:00,  3.21it/s]\n",
      "Extracting features in batches: 100%|██████████| 50/50 [00:23<00:00,  2.16it/s]\n",
      "\n",
      "Extracting features in batches:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Extracting features in batches:  20%|██        | 2/10 [00:00<00:01,  6.06it/s]\n",
      "Extracting features in batches:  30%|███       | 3/10 [00:00<00:01,  4.42it/s]\n",
      "Extracting features in batches:  40%|████      | 4/10 [00:00<00:01,  3.87it/s]\n",
      "Extracting features in batches:  50%|█████     | 5/10 [00:01<00:01,  3.61it/s]\n",
      "Extracting features in batches:  60%|██████    | 6/10 [00:01<00:01,  3.46it/s]\n",
      "Extracting features in batches:  70%|███████   | 7/10 [00:01<00:00,  3.38it/s]\n",
      "Extracting features in batches:  80%|████████  | 8/10 [00:02<00:00,  3.30it/s]\n",
      "Extracting features in batches:  90%|█████████ | 9/10 [00:02<00:00,  3.26it/s]\n",
      "Extracting features in batches: 100%|██████████| 10/10 [00:02<00:00,  3.27it/s]\n",
      "Extracting features in batches: 100%|██████████| 10/10 [00:02<00:00,  3.54it/s]\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "source": [
    "### 2. MultiLabel Binary image classification pressure (MLB)\n",
    "As our first pressure, the system additionally predicts for each image (distractors and target image) whether it is of the same class as the target image. The total loss is the loss for that task summed with the standard signaling game loss."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-03-28 18:35:03.666160: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\n",
      "Log path: 28_03_2021_18_35_00_task_img_clas_seed_7\n",
      "\n",
      "\n",
      "Extracting features in batches:   0%|          | 0/50 [00:00<?, ?it/s]Parameters specified in the command line:\n",
      "Extracting features in batches:   2%|▏         | 1/50 [00:07<06:02,  7.40s/it]\n",
      "Image classification task: img_clas\n",
      "Extracting features in batches:   4%|▍         | 2/50 [00:07<02:33,  3.20s/it]\n"
     ]
    }
   ],
   "source": [
    "!python main.py --task img_clas"
   ]
  },
  {
   "source": [
    "### 3. Multiclass image classification pressure\n",
    "As the second pressure, they system additionally predicts the target class of the target image. The total loss is the loss for that task summed with the standard signaling game loss."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "Game type:  SenderReceiverRnnGS\n",
      "Extracting features in batches:   6%|▌         | 3/50 [00:07<01:28,  1.89s/it]Image classification loss weight:  1.0\n",
      "\n",
      "Extracting features in batches:   8%|▊         | 4/50 [00:08<00:58,  1.26s/it]Number of images in the game:  2\n",
      "Extracting features in batches:  10%|█         | 5/50 [00:08<00:41,  1.09it/s]\n",
      "Same class probability:  0.0\n",
      "\n",
      "Extracting features in batches:  12%|█▏        | 6/50 [00:08<00:31,  1.40it/s]Evaluate on Gaussian noise images? False\n",
      "\n",
      "Extracting features in batches:  14%|█▍        | 7/50 [00:09<00:25,  1.72it/s]\n",
      "\n",
      "Extracting features in batches:  16%|█▌        | 8/50 [00:09<00:20,  2.01it/s]Cell type of the agents: gru\n",
      "Extracting features in batches:  18%|█▊        | 9/50 [00:09<00:17,  2.28it/s]\n",
      "Device: cuda\n",
      "Extracting features in batches:  20%|██        | 10/50 [00:10<00:15,  2.50it/s]\n",
      "Files already downloaded and verified\n",
      "Extracting features in batches:  22%|██▏       | 11/50 [00:10<00:14,  2.68it/s]\n",
      "\n",
      "Extract image features from train set\n",
      "Extracting features in batches:  24%|██▍       | 12/50 [00:10<00:13,  2.83it/s]Extract image features from test set Cifar100\n",
      "Extracting features in batches:  26%|██▌       | 13/50 [00:11<00:12,  2.93it/s]\n",
      "\n",
      "Start trainingExtracting features in batches:  28%|██▊       | 14/50 [00:11<00:11,  3.01it/s]\n",
      "{\"loss\": 0.4066273272037506, \"acc\": 0.8157200217247009, \"img_class_acc\": 0.7587000131607056, \"length\": 2.7555201053619385, \"mode\": \"train\", \"epoch\": 1}\n",
      "\n",
      "Extracting features in batches:  30%|███       | 15/50 [00:11<00:11,  3.07it/s]\n",
      "{\"loss\": 0.22377893328666687, \"acc\": 0.9319000244140625, \"img_class_acc\": 0.8821499943733215, \"length\": 3.1426000595092773, \"mode\": \"test\", \"epoch\": 1}\n",
      "Extracting features in batches:  32%|███▏      | 16/50 [00:12<00:10,  3.11it/s]{\"loss\": 0.20000377297401428, \"acc\": 0.9451599717140198, \"img_class_acc\": 0.8904100060462952, \"length\": 4.749000072479248, \"mode\": \"train\", \"epoch\": 2}\n",
      "Extracting features in batches:  34%|███▍      | 17/50 [00:12<00:10,  3.14it/s]\n",
      "\n",
      "{\"loss\": 0.1727411150932312, \"acc\": 0.955299973487854, \"img_class_acc\": 0.9121500253677368, \"length\": 4.611999988555908, \"mode\": \"test\", \"epoch\": 2}Extracting features in batches:  36%|███▌      | 18/50 [00:12<00:10,  3.16it/s]\n",
      "{\"loss\": 0.14450399577617645, \"acc\": 0.96697998046875, \"img_class_acc\": 0.9272400140762329, \"length\": 6.506159782409668, \"mode\": \"train\", \"epoch\": 3}\n",
      "\n",
      "{\"loss\": 0.14457595348358154, \"acc\": 0.9735000133514404, \"img_class_acc\": 0.9287999868392944, \"length\": 7.008900165557861, \"mode\": \"test\", \"epoch\": 3}Extracting features in batches:  38%|███▊      | 19/50 [00:12<00:09,  3.18it/s]\n",
      "\n",
      "Extracting features in batches:  40%|████      | 20/50 [00:13<00:09,  3.19it/s]\n",
      "Extracting features in batches:  42%|████▏     | 21/50 [00:13<00:09,  3.20it/s]\n",
      "Extracting features in batches:  44%|████▍     | 22/50 [00:13<00:08,  3.20it/s]\n",
      "Extracting features in batches:  46%|████▌     | 23/50 [00:14<00:08,  3.18it/s]\n",
      "Extracting features in batches:  48%|████▊     | 24/50 [00:14<00:08,  3.21it/s]\n",
      "Extracting features in batches:  50%|█████     | 25/50 [00:14<00:07,  3.21it/s]\n",
      "Extracting features in batches:  52%|█████▏    | 26/50 [00:15<00:07,  3.21it/s]\n",
      "Extracting features in batches:  54%|█████▍    | 27/50 [00:15<00:07,  3.21it/s]\n",
      "Extracting features in batches:  56%|█████▌    | 28/50 [00:15<00:06,  3.21it/s]\n",
      "Extracting features in batches:  58%|█████▊    | 29/50 [00:16<00:06,  3.21it/s]\n",
      "Extracting features in batches:  60%|██████    | 30/50 [00:16<00:06,  3.21it/s]\n",
      "Extracting features in batches:  62%|██████▏   | 31/50 [00:16<00:05,  3.21it/s]\n",
      "Extracting features in batches:  64%|██████▍   | 32/50 [00:17<00:05,  3.21it/s]\n",
      "Extracting features in batches:  66%|██████▌   | 33/50 [00:17<00:05,  3.21it/s]\n",
      "Extracting features in batches:  68%|██████▊   | 34/50 [00:17<00:04,  3.21it/s]\n",
      "Extracting features in batches:  70%|███████   | 35/50 [00:17<00:04,  3.21it/s]\n",
      "Extracting features in batches:  72%|███████▏  | 36/50 [00:18<00:04,  3.21it/s]\n",
      "Extracting features in batches:  74%|███████▍  | 37/50 [00:18<00:04,  3.21it/s]\n",
      "Extracting features in batches:  76%|███████▌  | 38/50 [00:18<00:03,  3.21it/s]\n",
      "Extracting features in batches:  78%|███████▊  | 39/50 [00:19<00:03,  3.21it/s]\n",
      "Extracting features in batches:  80%|████████  | 40/50 [00:19<00:03,  3.21it/s]\n",
      "Extracting features in batches:  82%|████████▏ | 41/50 [00:19<00:02,  3.21it/s]\n",
      "Extracting features in batches:  84%|████████▍ | 42/50 [00:20<00:02,  3.21it/s]\n",
      "Extracting features in batches:  86%|████████▌ | 43/50 [00:20<00:02,  3.21it/s]\n",
      "Extracting features in batches:  88%|████████▊ | 44/50 [00:20<00:01,  3.21it/s]\n",
      "Extracting features in batches:  90%|█████████ | 45/50 [00:21<00:01,  3.21it/s]\n",
      "Extracting features in batches:  92%|█████████▏| 46/50 [00:21<00:01,  3.21it/s]\n",
      "Extracting features in batches:  94%|█████████▍| 47/50 [00:21<00:00,  3.21it/s]\n",
      "Extracting features in batches:  96%|█████████▌| 48/50 [00:21<00:00,  3.21it/s]\n",
      "Extracting features in batches:  98%|█████████▊| 49/50 [00:22<00:00,  3.21it/s]\n",
      "Extracting features in batches: 100%|██████████| 50/50 [00:22<00:00,  3.21it/s]\n",
      "Extracting features in batches: 100%|██████████| 50/50 [00:22<00:00,  2.21it/s]\n",
      "\n",
      "Extracting features in batches:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Extracting features in batches:  20%|██        | 2/10 [00:00<00:01,  5.95it/s]\n",
      "Extracting features in batches:  30%|███       | 3/10 [00:00<00:01,  4.39it/s]\n",
      "Extracting features in batches:  40%|████      | 4/10 [00:00<00:01,  3.89it/s]\n",
      "Extracting features in batches:  50%|█████     | 5/10 [00:01<00:01,  3.63it/s]\n",
      "Extracting features in batches:  60%|██████    | 6/10 [00:01<00:01,  3.48it/s]\n",
      "Extracting features in batches:  70%|███████   | 7/10 [00:01<00:00,  3.38it/s]\n",
      "Extracting features in batches:  80%|████████  | 8/10 [00:02<00:00,  3.33it/s]\n",
      "Extracting features in batches:  90%|█████████ | 9/10 [00:02<00:00,  3.29it/s]\n",
      "Extracting features in batches: 100%|██████████| 10/10 [00:02<00:00,  3.26it/s]\n",
      "Extracting features in batches: 100%|██████████| 10/10 [00:02<00:00,  3.54it/s]\n",
      "2021-03-28 18:40:40.910747: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\n",
      "\n",
      "Log path: 28_03_2021_18_40_40_task_target_clas_seed_7\n",
      "Extracting features in batches:   0%|          | 0/50 [00:00<?, ?it/s]\n",
      "\n",
      "Parameters specified in the command line:Extracting features in batches:   2%|▏         | 1/50 [00:01<01:03,  1.30s/it]\n",
      "\n",
      "Image classification task: target_clasExtracting features in batches:   4%|▍         | 2/50 [00:01<00:34,  1.38it/s]\n",
      "\n",
      "Game type:  SenderReceiverRnnGS\n",
      "Extracting features in batches:   6%|▌         | 3/50 [00:01<00:25,  1.84it/s]Image classification loss weight:  1.0\n",
      "\n",
      "Extracting features in batches:   8%|▊         | 4/50 [00:02<00:20,  2.23it/s]Number of images in the game:  2\n",
      "\n",
      "Same class probability:  0.0Extracting features in batches:  10%|█         | 5/50 [00:02<00:17,  2.51it/s]\n",
      "\n",
      "Evaluate on Gaussian noise images? FalseExtracting features in batches:  12%|█▏        | 6/50 [00:02<00:16,  2.71it/s]\n",
      "\n",
      "Extracting features in batches:  14%|█▍        | 7/50 [00:03<00:15,  2.84it/s]\n",
      "Cell type of the agents: gru\n",
      "Extracting features in batches:  16%|█▌        | 8/50 [00:03<00:14,  2.96it/s]\n",
      "\n",
      "Device: cudaExtracting features in batches:  18%|█▊        | 9/50 [00:03<00:13,  3.03it/s]\n",
      "Files already downloaded and verified\n",
      "\n",
      "Extract image features from train set\n",
      "Extracting features in batches:  20%|██        | 10/50 [00:04<00:12,  3.08it/s]Extract image features from test set Cifar100\n",
      "\n",
      "Extracting features in batches:  22%|██▏       | 11/50 [00:04<00:12,  3.12it/s]Start training\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python main.py --task target_clas"
   ]
  },
  {
   "source": [
    "## Reproducing paper results\n",
    "In this section, we reproduce the results presented in the paper. Bear in mind that these experiments take in total 10-20 hours to run on a GPU."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Table 1 from the paper"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_multiple.py"
   ]
  },
  {
   "source": [
    "Running above code will output a list of log names for all runs. Now we will gather the results and create a table to summarize them. Copy this list in the cell below and run the next cells."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_names = ['27_03_2021_21_13_38_task_standard_seed_7', '27_03_2021_21_18_39_task_standard_seed_122', '27_03_2021_21_22_35_task_standard_seed_809', '27_03_2021_21_26_32_task_standard_seed_7', '27_03_2021_21_37_58_task_standard_seed_122', '27_03_2021_21_46_57_task_standard_seed_809', '27_03_2021_21_58_31_task_standard_seed_7', '27_03_2021_22_10_58_task_standard_seed_122', '27_03_2021_22_23_37_task_standard_seed_809', '27_03_2021_22_35_48_task_img_clas_seed_7', '27_03_2021_22_40_54_task_img_clas_seed_122', '27_03_2021_22_52_54_task_img_clas_seed_809', '27_03_2021_22_57_58_task_img_clas_seed_7', '27_03_2021_23_12_40_task_img_clas_seed_122', '27_03_2021_23_28_27_task_img_clas_seed_809', '27_03_2021_23_43_42_task_img_clas_seed_7', '27_03_2021_23_59_23_task_img_clas_seed_122', '28_03_2021_00_13_58_task_img_clas_seed_809', '28_03_2021_00_58_18_task_target_clas_seed_7', '28_03_2021_01_04_29_task_target_clas_seed_122', '28_03_2021_01_09_23_task_target_clas_seed_809', '28_03_2021_01_23_40_task_target_clas_seed_7', '28_03_2021_01_37_44_task_target_clas_seed_122', '28_03_2021_01_52_23_task_target_clas_seed_809', '28_03_2021_03_06_28_task_target_clas_seed_7', '28_03_2021_03_20_31_task_target_clas_seed_122', '28_03_2021_03_34_47_task_target_clas_seed_809']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "\n",
    "def load_metric_from_event(event_name): \n",
    "    event_path = os.path.join(\"runs\", event_name)\n",
    "    event_name = os.listdir(event_path)[0]\n",
    "    event_path = os.path.join(event_path, event_name)\n",
    "\n",
    "    # only read scalars\n",
    "    ea = event_accumulator.EventAccumulator(event_path, size_guidance={event_accumulator.SCALARS: 0})\n",
    "\n",
    "    # load scalars\n",
    "    ea.Reload()\n",
    "\n",
    "    return get_best_epoch_metrics(ea)\n",
    "\n",
    "def get_best_epoch_metrics(ea):\n",
    "    test_accs = ea.Scalars(f\"test/acc\")\n",
    "    test_acc_vals = [acc.value for acc in test_accs]\n",
    "    test_best_acc_idx = np.argmax(test_acc_vals)\n",
    "    test_best_acc = np.max(test_acc_vals)\n",
    "    test_best_epoch = test_accs[test_best_acc_idx].step\n",
    "\n",
    "    train_accs = ea.Scalars(f\"train/acc\")\n",
    "    train_best_acc = train_accs[test_best_acc_idx].value\n",
    "    try:\n",
    "        train_img_clas_accs = ea.Scalars(f\"train/img_class_acc\")\n",
    "        train_best_img_clas_acc = train_img_clas_accs[test_best_acc_idx].value\n",
    "\n",
    "        \n",
    "        test_img_clas_accs = ea.Scalars(f\"train/img_class_acc\")\n",
    "        test_best_img_clas_acc = test_img_clas_accs[test_best_acc_idx].value\n",
    "    except KeyError:\n",
    "        train_best_img_clas_acc = np.nan\n",
    "        test_best_img_clas_acc = np.nan\n",
    "    \n",
    "    return [test_best_epoch, train_best_acc, test_best_acc, train_best_img_clas_acc, test_best_img_clas_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose which params to include in the\n",
    "include_params = [\"task\", \"ic_loss_weight\", \"num_imgs\", \"same_class_prob\", \"seed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       task  ic_loss_weight  num_imgs  same_class_prob  seed  best epoch  \\\n",
       "0  standard           1.000         2            0.000     7           4   \n",
       "0  standard           1.000         2            0.000   122           3   \n",
       "0  standard           1.000         2            0.000   809           3   \n",
       "0  standard           1.000         2            0.500     7          10   \n",
       "0  standard           1.000         2            0.500   122           7   \n",
       "\n",
       "   best train acc  best test acc  best train img acc  best test img acc  \\\n",
       "0           0.974          0.978                 nan                nan   \n",
       "0           0.968          0.978                 nan                nan   \n",
       "0           0.968          0.973                 nan                nan   \n",
       "0           0.933          0.954                 nan                nan   \n",
       "0           0.955          0.970                 nan                nan   \n",
       "\n",
       "   noise acc  \n",
       "0      0.644  \n",
       "0      0.766  \n",
       "0      0.795  \n",
       "0      0.824  \n",
       "0      0.734  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>task</th>\n      <th>ic_loss_weight</th>\n      <th>num_imgs</th>\n      <th>same_class_prob</th>\n      <th>seed</th>\n      <th>best epoch</th>\n      <th>best train acc</th>\n      <th>best test acc</th>\n      <th>best train img acc</th>\n      <th>best test img acc</th>\n      <th>noise acc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>standard</td>\n      <td>1.000</td>\n      <td>2</td>\n      <td>0.000</td>\n      <td>7</td>\n      <td>4</td>\n      <td>0.974</td>\n      <td>0.978</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>0.644</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>standard</td>\n      <td>1.000</td>\n      <td>2</td>\n      <td>0.000</td>\n      <td>122</td>\n      <td>3</td>\n      <td>0.968</td>\n      <td>0.978</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>0.766</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>standard</td>\n      <td>1.000</td>\n      <td>2</td>\n      <td>0.000</td>\n      <td>809</td>\n      <td>3</td>\n      <td>0.968</td>\n      <td>0.973</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>0.795</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>standard</td>\n      <td>1.000</td>\n      <td>2</td>\n      <td>0.500</td>\n      <td>7</td>\n      <td>10</td>\n      <td>0.933</td>\n      <td>0.954</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>0.824</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>standard</td>\n      <td>1.000</td>\n      <td>2</td>\n      <td>0.500</td>\n      <td>122</td>\n      <td>7</td>\n      <td>0.955</td>\n      <td>0.970</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>0.734</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "results = []\n",
    "for event_name in log_names:\n",
    "    # get parameters\n",
    "    with open(f\"args//args_{event_name}.json\") as json_file:\n",
    "        params = json.load(json_file)\n",
    "    # wrap each value into a list\n",
    "    params = {key:[value] for key, value in params.items()}\n",
    "\n",
    "    # create dataframe and add parameters\n",
    "    results_df = pd.DataFrame(params)[include_params]\n",
    "\n",
    "    # add metrics\n",
    "    metric_cols = [\"best epoch\", \"best train acc\", \"best test acc\", \"best train img acc\", \"best test img acc\"]\n",
    "    results_df.loc[:, metric_cols] = load_metric_from_event(event_name)\n",
    "\n",
    "    # add noise acc\n",
    "    try:\n",
    "        path = f'interactions//{event_name}//validation'\n",
    "        interactions = torch.load(f\"{path}//interactions_epoch11\")\n",
    "        results_df[\"noise acc\"] = interactions.aux[\"acc\"].mean().item()\n",
    "    except FileNotFoundError:\n",
    "        results_df[\"noise acc\"] = 0.0\n",
    "\n",
    "    # append to final table\n",
    "    results.append(results_df)\n",
    "\n",
    "\n",
    "results = pd.concat(results)\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "pearson = pearsonr(results[\"best test acc\"], results[\"noise acc\"])\n",
    "spearman = spearmanr(results[\"best test acc\"], results[\"noise acc\"])\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                             best test acc best test img acc\n",
       "task        same_class_prob                                 \n",
       "standard    0.000                    0.976                 -\n",
       "            0.500                    0.955                 -\n",
       "            1.000                    0.945                 -\n",
       "img_clas    0.000                    0.973             0.918\n",
       "            0.500                    0.923             0.856\n",
       "            1.000                    0.935             1.000\n",
       "target_clas 0.000                    0.972             0.379\n",
       "            0.500                    0.918             0.455\n",
       "            1.000                    0.905             0.414"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>best test acc</th>\n      <th>best test img acc</th>\n    </tr>\n    <tr>\n      <th>task</th>\n      <th>same_class_prob</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">standard</th>\n      <th>0.000</th>\n      <td>0.976</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>0.500</th>\n      <td>0.955</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>1.000</th>\n      <td>0.945</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">img_clas</th>\n      <th>0.000</th>\n      <td>0.973</td>\n      <td>0.918</td>\n    </tr>\n    <tr>\n      <th>0.500</th>\n      <td>0.923</td>\n      <td>0.856</td>\n    </tr>\n    <tr>\n      <th>1.000</th>\n      <td>0.935</td>\n      <td>1.000</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">target_clas</th>\n      <th>0.000</th>\n      <td>0.972</td>\n      <td>0.379</td>\n    </tr>\n    <tr>\n      <th>0.500</th>\n      <td>0.918</td>\n      <td>0.455</td>\n    </tr>\n    <tr>\n      <th>1.000</th>\n      <td>0.905</td>\n      <td>0.414</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# results[\"success\"] = (results[\"best test acc\"]>0.97).astype(int)\n",
    "results = results.groupby(by=[\"task\", \"same_class_prob\"]).mean()\n",
    "results = results.reindex(index = ['standard','img_clas','target_clas'], level=\"task\").fillna('-')\n",
    "results[[\"best test acc\", \"best test img acc\"]]"
   ]
  },
  {
   "source": [
    "### Gaussian noise images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             best test acc  noise acc\n",
       "task                                 \n",
       "standard             0.955      0.809\n",
       "img_clas             0.923      0.746\n",
       "target_clas          0.918      0.594"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>best test acc</th>\n      <th>noise acc</th>\n    </tr>\n    <tr>\n      <th>task</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>standard</th>\n      <td>0.955</td>\n      <td>0.809</td>\n    </tr>\n    <tr>\n      <th>img_clas</th>\n      <td>0.923</td>\n      <td>0.746</td>\n    </tr>\n    <tr>\n      <th>target_clas</th>\n      <td>0.918</td>\n      <td>0.594</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "noise_results = results.reset_index(level=\"same_class_prob\")\n",
    "noise_results = noise_results.loc[noise_results[\"same_class_prob\"]==0.5,[\"best test acc\", \"noise acc\"]]\n",
    "noise_results"
   ]
  },
  {
   "source": [
    "##### Correlation between validation accuracy and noise accuracy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Pearson correlation: {pearson[0]} (p={np.round(pearson[1],2)})\")\n",
    "print(f\"Spearman correlation: {spearman.correlation} (p={np.round(spearman.pvalue, 2)})\")"
   ]
  },
  {
   "source": [
    "### Topographic Similarity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from egg.core.language_analysis import TopographicSimilarity\n",
    "\n",
    "def get_best_epoch(path):\n",
    "        best_epoch_score = 0.0\n",
    "        best_epoch = 1\n",
    "        epoch_interactions = os.listdir(path)[:-1] # without noise\n",
    "        for epoch, epoch_path in enumerate(epoch_interactions):\n",
    "            interactions = torch.load(f\"{path}//{epoch_path}\")\n",
    "            current_epoch_score = interactions.aux[\"acc\"].mean()\n",
    "            if current_epoch_score > best_epoch_score:\n",
    "                best_epoch_score = current_epoch_score\n",
    "                best_epoch = epoch+1\n",
    "        return best_epoch\n",
    "\n",
    "def get_params_df(log_name, include_params=[\"task\", \"same_class_prob\", \"seed\"]):\n",
    "     # get parameters\n",
    "    with open(f\"args//args_{log_name}.json\") as json_file:\n",
    "        params = json.load(json_file)\n",
    "\n",
    "    # wrap each value into a list\n",
    "    params = {key:[value] for key, value in params.items()}\n",
    "\n",
    "    # create dataframe and add parameters\n",
    "    results_df = pd.DataFrame(params)[include_params]\n",
    "    return results_df\n",
    "    \n",
    "def get_top_sim(log_name, size):\n",
    "    path = f'interactions//{log_name}//validation'\n",
    "    best_epoch = get_best_epoch(path)\n",
    "    interactions = torch.load(f\"{path}//interactions_epoch{best_epoch}\")\n",
    "    messages = np.argmax(interactions.message, axis=-1)\n",
    "    sender_input = interactions.sender_input.squeeze(dim=1)\n",
    "    random_idx = np.random.randint(low=0, high=sender_input.shape[0], size=size)\n",
    "    messages = messages[random_idx]\n",
    "    sender_input = sender_input[random_idx]\n",
    "    top_sim = TopographicSimilarity.compute_topsim(sender_input, messages, 'cosine', 'euclidean')\n",
    "\n",
    "    return top_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only calculate TS for runs with same class probability = 0.5\n",
    "selected_idxs = [3, 4, 5, 12, 13, 14, 21, 22, 23]\n",
    "log_names = [log_names[i] for i in range(len(log_names)) if i in selected_idxs]\n",
    "# log_names = ['27_03_2021_16_26_11_task_standard_seed_7', '27_03_2021_16_47_36_task_standard_seed_122']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 9/9 [5:26:08<00:00, 2174.22s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "top_sim_results = []\n",
    "size = 10000 # how many messages do you want to sample - (0, 10000]\n",
    "for log_name in tqdm(log_names):\n",
    "    \n",
    "    top_sim_results_df = get_params_df(log_name)\n",
    "    top_sim_results_df[\"top_sim\"] = get_top_sim(log_name, size=size)\n",
    "\n",
    "    # append to final table\n",
    "    top_sim_results.append(top_sim_results_df)\n",
    "\n",
    "top_sim = pd.concat(top_sim_results).groupby(by=\"task\").mean()"
   ]
  },
  {
   "source": [
    "top_sim"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 41,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             same_class_prob    seed  top_sim\n",
       "task                                         \n",
       "img_clas               0.500 312.667    0.049\n",
       "standard               0.500 312.667    0.119\n",
       "target_clas            0.500 312.667    0.176"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>same_class_prob</th>\n      <th>seed</th>\n      <th>top_sim</th>\n    </tr>\n    <tr>\n      <th>task</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>img_clas</th>\n      <td>0.500</td>\n      <td>312.667</td>\n      <td>0.049</td>\n    </tr>\n    <tr>\n      <th>standard</th>\n      <td>0.500</td>\n      <td>312.667</td>\n      <td>0.119</td>\n    </tr>\n    <tr>\n      <th>target_clas</th>\n      <td>0.500</td>\n      <td>312.667</td>\n      <td>0.176</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 41
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}