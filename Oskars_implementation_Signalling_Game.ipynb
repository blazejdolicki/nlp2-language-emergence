{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFI90Pje3SmG"
   },
   "source": [
    "# Template for variable length Signalling Game\n",
    "\n",
    "This template is based on the [MNIST autoencoder tutorial](https://github.com/facebookresearch/EGG/blob/master/tutorials/EGG%20walkthrough%20with%20a%20MNIST%20autoencoder.ipynb) and [signal game implementation](https://github.com/facebookresearch/EGG/blob/master/egg/zoo/signal_game) provided by the [EGG library](https://github.com/facebookresearch/EGG).\n",
    "\n",
    "Some code is provided by Mathieu Bartels and Liselore Borel Rinkes at the UvA.\n",
    "\n",
    "Make sure you have a directory `SignalGame` in your Drive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T10:22:04.171777Z",
     "start_time": "2021-03-14T10:22:02.728196Z"
    },
    "id": "ps5ruebXSmtj"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.spatial.distance as distance\n",
    "import scipy.stats\n",
    "import scipy\n",
    "import egg.core as core\n",
    "import egg.zoo as zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgJu9uxMLpj0"
   },
   "source": [
    "## Configuration\n",
    "Make sure to define some important configuration parameters in a convenient place, such as the number of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T10:22:06.396282Z",
     "start_time": "2021-03-14T10:22:04.171777Z"
    },
    "id": "ngBTgCFSLpQw"
   },
   "outputs": [],
   "source": [
    "import types\n",
    "import json\n",
    "\n",
    "# For convenience and reproducibility, we set some EGG-level command line arguments here\n",
    "opts = core.init(params=['--random_seed=7', # will initialize numpy, torch, and python RNGs\n",
    "                         '--lr=1e-3', # sets the learning rate for the selected optimizer \n",
    "                         '--batch_size=64',\n",
    "                         '--vocab_size=100',\n",
    "                         '--max_len=10',\n",
    "                         '--n_epochs=15',\n",
    "                         '--tensorboard',\n",
    "                         ]) \n",
    "\n",
    "_args_dict = {\n",
    "    \"architecture\" : {\n",
    "        \"embed_size\"      : 64,\n",
    "        \"hidden_sender\"   : 200,\n",
    "        \"hidden_receiver\" : 200,\n",
    "        \"cell_type\"       : 'gru',\n",
    "    },\n",
    "    \"game\" : {\n",
    "        \"num_classes\"     : 100, # defined by CIFAR-100\n",
    "        \"game_size\"       : 2,\n",
    "        # OTHER\n",
    "        \"sender_has_distractor\" : False,\n",
    "    },\n",
    "    \"training\" : {\n",
    "        \"temperature\"     : 1,\n",
    "    },\n",
    "}\n",
    "\n",
    "args = json.loads(json.dumps(_args_dict), object_hook=lambda item: types.SimpleNamespace(**item))\n",
    "\n",
    "# TODO: other configurations?\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRHxMztINp6W"
   },
   "source": [
    "## Vision\n",
    "The vision model is used in this template to create embeddings for the input images. The code below imports a vision module for the [CIFAR-100 dataset](https://www.cs.toronto.edu/~kriz/cifar.html). However, you can also choose for making the visual unit part of the agent architecture and update/train it during the game (as in the MNIST tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T10:22:08.243444Z",
     "start_time": "2021-03-14T10:22:06.396282Z"
    },
    "id": "ROz8NxGJKC_W"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vision(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=64, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Vision(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=100):\n",
    "        super(Vision, self).__init__()\n",
    "        self.inplanes = 16\n",
    "        self.conv1 = conv3x3(3, 16)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(64 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def classify(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    " \n",
    "# load pre-trained parameters\n",
    "num_classes = 100\n",
    "restnet_location = \"https://github.com/chenyaofo/CIFAR-pretrained-models/releases/download/resnet/cifar100-resnet56-2f147f26.pth\"\n",
    "vision = Vision(BasicBlock, [9, 9, 9], num_classes=num_classes).to(device)\n",
    "vision.load_state_dict(model_zoo.load_url(restnet_location))\n",
    "\n",
    "vision.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FsjKgmmxKONz"
   },
   "source": [
    "## Data\n",
    "Implement a custom dataset to be used in the Signalling Game, building on top of a Dataset of your choice (e.g. CIFAR-100).\n",
    "*You could use the below code to train a featuriser for CIFAR-100 or implement your own!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T10:22:10.172546Z",
     "start_time": "2021-03-14T10:22:08.245366Z"
    },
    "id": "beE1Gto8bR72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#kwargs = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
    "#kwargs = {'num_workers': 1, 'pin_memory': True} if device==torch.device(\"cuda\") else {}\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop(size=32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5071, 0.4865, 0.4409],\n",
    "        std=[0.2009, 0.1984, 0.2023]\n",
    "    ),\n",
    "])\n",
    "\n",
    "train_set = datasets.CIFAR100('./data', train=True, download=True, transform=transform)\n",
    "\n",
    "test_set = datasets.CIFAR100('./data', train=False, transform=transform)\n",
    "\n",
    "test_set_originals = datasets.CIFAR100('./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "checking_test_loader = torch.utils.data.DataLoader(test_set, shuffle=False,\n",
    "                                         batch_size=opts.batch_size, num_workers=2)\n",
    "\n",
    "# Set to True if you want to evaluate the vision_model\n",
    "eval_vision_model = False\n",
    "\n",
    "if eval_vision_model:\n",
    "  mean_loss, mean_acc, n_batches = 0, 0, 0\n",
    "  for batch_idx, (data, target) in enumerate(checking_test_loader):\n",
    "      with torch.no_grad():\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = vision.classify(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "\n",
    "        mean_loss += loss.mean().item()\n",
    "        mean_acc += (target == output.argmax(dim=1)).float().mean().item()\n",
    "        n_batches += 1\n",
    "      \n",
    "  print(f' mean loss: {mean_loss / n_batches}, mean acc: {mean_acc / n_batches}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T10:22:10.204543Z",
     "start_time": "2021-03-14T10:22:10.174545Z"
    },
    "id": "J9cxLMFkMMi0"
   },
   "outputs": [],
   "source": [
    "def get_random_indices(excluded, range, amount):\n",
    "  indices = random.sample(range, amount)\n",
    "  while excluded in indices:\n",
    "    indices = random.sample(range, amount)\n",
    "  return indices\n",
    "\n",
    "class SignalGameDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, game_size, vision, embedding_size, dataset_name, device, sender_has_distractor=True, classes=None):\n",
    "        self.dataset = dataset\n",
    "        self.game_size = game_size\n",
    "        self.vision = vision\n",
    "        self.dataset_name = dataset_name\n",
    "        self.embedding_size = embedding_size\n",
    "        self.embeddings = self.pre_process_image_embeddings(16)\n",
    "        self.sender_has_distractor = sender_has_distractor\n",
    "        self.device = device\n",
    "\n",
    "    def pre_process_image_embeddings(self, batch_size):\n",
    "        if os.path.isfile(f\"image_embeddings_{self.dataset_name}.pkl\"):\n",
    "            return torch.load( open(f\"image_embeddings_{self.dataset_name}.pkl\", \"rb\" ) )\n",
    "        trainloader = torch.utils.data.DataLoader(self.dataset, shuffle=False,\n",
    "                                          batch_size=batch_size, num_workers=2)\n",
    "        \n",
    "        image_embeddings = torch.zeros((len(self.dataset), self.embedding_size))\n",
    "        labels = torch.zeros(len(self.dataset))\n",
    "        for i, (x, y) in enumerate(tqdm(trainloader)):\n",
    "          x = x.to(device)\n",
    "          with torch.no_grad():\n",
    "            embedding = self.vision(x).cpu()\n",
    "          image_embeddings[i*batch_size:(i+1) * batch_size, :] = embedding\n",
    "          labels[i*batch_size:(i+1) * batch_size] = y\n",
    "        \n",
    "        torch.save(image_embeddings, open(f\"image_embeddings_{self.dataset_name}.pkl\", \"wb\" ))\n",
    "        return image_embeddings\n",
    "\n",
    "    def get_item_info(self, index):\n",
    "        image, classlabel = self.dataset[index]\n",
    "        return image, classlabel\n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        dataset = self.embeddings\n",
    "        game_size = self.game_size\n",
    "        target_image = dataset[item]\n",
    "\n",
    "        indices = get_random_indices(item, range(self.__len__()), game_size-1)\n",
    "        images = [target_image] + [dataset[indice] for indice in indices]\n",
    "\n",
    "        sender_images = torch.stack(images, dim=0)\n",
    "\n",
    "        perm = torch.randperm(game_size)\n",
    "        receiver_imgs = sender_images[perm]\n",
    "        target = torch.argmin(perm)\n",
    "        \n",
    "        if not self.sender_has_distractor:\n",
    "            sender_images = target_image\n",
    "\n",
    "        return sender_images, target, receiver_imgs\n",
    "\n",
    "trainset = SignalGameDataset(train_set, args.game.game_size, vision, args.architecture.embed_size, 'train',\n",
    "                             device,sender_has_distractor=args.game.sender_has_distractor)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, shuffle=True,\n",
    "                                          batch_size=opts.batch_size, num_workers=0) #was 2\n",
    "\n",
    "testset = SignalGameDataset(test_set, args.game.game_size, vision, args.architecture.embed_size, 'test',\n",
    "                            device,sender_has_distractor=args.game.sender_has_distractor)\n",
    "testloader = torch.utils.data.DataLoader(testset, shuffle=False,\n",
    "                                         batch_size=opts.batch_size, num_workers=0) # was 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuIkT8KqK_fz"
   },
   "source": [
    "## Agent design\n",
    "We can use the Rnn Wrappers from EGG to implement a recurrent neural agent on top of your Sender and Receiver design. Here the Gumbel Softmax (GS) is used, but you can also use a [Reinforce Wrapper](https://github.com/facebookresearch/EGG/blob/master/egg/core/reinforce_wrappers.py).\n",
    "\n",
    "See [RnnSenderGS and RnnReceiverGS](https://github.com/facebookresearch/EGG/blob/master/egg/core/gs_wrappers.py) in the documentation for what happens under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6e77C67LH1U"
   },
   "source": [
    "### Sender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T10:22:10.220551Z",
     "start_time": "2021-03-14T10:22:10.206547Z"
    },
    "id": "Av7icZpFN6Wj"
   },
   "outputs": [],
   "source": [
    "class Sender(nn.Module):\n",
    "    def __init__(self, embed_size, game_size, hidden_sender):\n",
    "      super(Sender, self).__init__()\n",
    "      self.embed_size = embed_size\n",
    "      self.game_size = game_size\n",
    "      \n",
    "      self.lin4 = nn.Linear(embed_size * game_size, hidden_sender, bias=True)\n",
    "        \n",
    "    def forward(self, imgs):\n",
    "      # imgs shape sender torch.Size([batch, embed_size])\n",
    "      out = self.lin4(imgs.view(-1, self.embed_size * self.game_size)).tanh()\n",
    "      # out shape sender torch.Size([64, 200])\n",
    "      return out\n",
    "\n",
    "if args.game.sender_has_distractor:\n",
    "    sender = Sender(args.architecture.embed_size, args.game.game_size, args.architecture.hidden_sender)\n",
    "else:\n",
    "    sender = Sender(args.architecture.embed_size, 1, args.architecture.hidden_sender)\n",
    "\n",
    "sender = core.RnnSenderGS(sender, opts.vocab_size, args.architecture.embed_size, args.architecture.hidden_sender, cell=args.architecture.cell_type,\n",
    "                        max_len=opts.max_len, temperature=args.training.temperature, straight_through=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oP1wc2jlLQky"
   },
   "source": [
    "### Receiver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T10:22:10.236545Z",
     "start_time": "2021-03-14T10:22:10.222551Z"
    },
    "id": "4ro77SNUS1rN"
   },
   "outputs": [],
   "source": [
    "class Receiver(nn.Module):\n",
    "  def __init__(self, hidden_receiver, embed_size):\n",
    "    super(Receiver, self).__init__()\n",
    "    self.embedding_size = embed_size\n",
    "\n",
    "    self.fc1 = nn.Linear(embed_size, hidden_receiver)\n",
    "\n",
    "  def forward(self, message, imgs):\n",
    "    # imgs shape  torch.Size([64, 2, 64])\n",
    "    # torch.Size([batch_size, game_size, hidden_size])\n",
    "    embedded_input = self.fc1(imgs).tanh()\n",
    "    \n",
    "    # message shape torch.Size([batch, hidden])\n",
    "    # torch.Size([batch_size, game_size, 1])\n",
    "    energies = torch.matmul(embedded_input, torch.unsqueeze(message, dim=-1))\n",
    "\n",
    "    return energies.squeeze()\n",
    "\n",
    "receiver = Receiver(args.architecture.hidden_receiver, args.architecture.embed_size)\n",
    "receiver = core.RnnReceiverGS(receiver, opts.vocab_size, args.architecture.embed_size,\n",
    "                    args.architecture.hidden_receiver, cell=args.architecture.cell_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1gSNpSoLUe5"
   },
   "source": [
    "# Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T10:22:10.252623Z",
     "start_time": "2021-03-14T10:22:10.239546Z"
    },
    "id": "CP3N2OPlS_qk"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def loss(_sender_input,  _message, _receiver_input, receiver_output, _labels):\n",
    "    acc = (receiver_output.argmax(dim=1) == _labels).detach().float()\n",
    "    loss = F.cross_entropy(receiver_output, _labels, reduction=\"none\")\n",
    "    # print('Loss: ', loss.mean().cpu().item(), 'Acc: ', acc.mean().cpu().item())\n",
    "    return loss, {'acc': acc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnCBbeyoLYPw"
   },
   "source": [
    "## Game setup and training\n",
    "Use `core.SenderReceiverRnnGS` for creating a variable message length game, set the optimizer and other options, and start training the agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T10:22:10.268596Z",
     "start_time": "2021-03-14T10:22:10.254549Z"
    },
    "id": "PCVqdUY1TCKX"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T10:22:10.284552Z",
     "start_time": "2021-03-14T10:22:10.270548Z"
    },
    "id": "U8og00m4e7tF"
   },
   "outputs": [],
   "source": [
    "model_prefix = f\"multi_target_max_len_{opts.max_len}\"\n",
    "models_path = \"/content/gdrive/My Drive/SignalGame/models\"\n",
    "\n",
    "checkpointer = core.callbacks.CheckpointSaver(checkpoint_path=models_path, checkpoint_freq=0, prefix=model_prefix)\n",
    "early_stopper = core.early_stopping.EarlyStopperAccuracy(threshold = 0.1)\n",
    "logger = core.callbacks.ConsoleLogger(print_train_loss=True)\n",
    "temperature_update = core.TemperatureUpdater(agent=sender, decay=0.9, minimum=0.1)\n",
    "\n",
    "#callbacks = [checkpointer, early_stopper, logger, temperature_update]\n",
    "checkpointer_class = core.callbacks.CheckpointSaver(checkpoint_path=models_path, checkpoint_freq=0, prefix=model_prefix+\"_class\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T10:22:10.300552Z",
     "start_time": "2021-03-14T10:22:10.286583Z"
    },
    "id": "1xdWxbaBfMC5"
   },
   "outputs": [],
   "source": [
    "game = core.SenderReceiverRnnGS(sender, receiver, loss)\n",
    "optimizer = torch.optim.Adam(game.parameters())\n",
    "\n",
    "callbacks = [core.TemperatureUpdater(agent=sender, decay=0.9, minimum=0.1),\n",
    "             core.ConsoleLogger(as_json=True, print_train_loss=True),\n",
    "             core.TensorboardLogger(),\n",
    "             core.EarlyStopperAccuracy(0.97)]\n",
    "\n",
    "trainer = core.Trainer(\n",
    "    game=game, optimizer=optimizer, train_data=trainloader,\n",
    "    validation_data=testloader, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T10:24:57.347393Z",
     "start_time": "2021-03-14T10:22:10.302546Z"
    },
    "id": "MOJw2EBvfRk9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loss\": 0.3063197135925293, \"acc\": 0.8298199772834778, \"length\": 7.104320049285889, \"mode\": \"train\", \"epoch\": 1}\n",
      "{\"loss\": 0.1404149830341339, \"acc\": 0.9340000152587891, \"length\": 10.236499786376953, \"mode\": \"test\", \"epoch\": 1}\n",
      "{\"loss\": 0.08692803978919983, \"acc\": 0.9606999754905701, \"length\": 9.655579566955566, \"mode\": \"train\", \"epoch\": 2}\n",
      "{\"loss\": 0.07190242409706116, \"acc\": 0.9686999917030334, \"length\": 10.068300247192383, \"mode\": \"test\", \"epoch\": 2}\n",
      "{\"loss\": 0.05964502692222595, \"acc\": 0.9736199975013733, \"length\": 10.071399688720703, \"mode\": \"train\", \"epoch\": 3}\n",
      "{\"loss\": 0.04568062350153923, \"acc\": 0.9797000288963318, \"length\": 9.040800094604492, \"mode\": \"test\", \"epoch\": 3}\n"
     ]
    }
   ],
   "source": [
    "trainer.train(n_epochs=opts.n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T10:24:57.378397Z",
     "start_time": "2021-03-14T10:24:57.348394Z"
    },
    "id": "i4rEbi4WThKw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_nA9yyIMt9r"
   },
   "source": [
    "## Evaluation of the emergent languages\n",
    "Next up, start analysing the languages and other behaviour you are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:21:05.741674Z",
     "start_time": "2021-03-14T13:21:04.520771Z"
    },
    "id": "spk0WEl8Q01U"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'game' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-45f4faae6153>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Check out https://github.com/facebookresearch/EGG/blob/aba2489e78f0b6e202bf2c6138fde41bf9056cb5/egg/zoo/objects_game/util.py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msender_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreceiver_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreceiver_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdump_sender_receiver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmessages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmessage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmessages\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmessages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'game' is not defined"
     ]
    }
   ],
   "source": [
    "from egg.zoo.objects_game.util import dump_sender_receiver\n",
    "# Check out https://github.com/facebookresearch/EGG/blob/aba2489e78f0b6e202bf2c6138fde41bf9056cb5/egg/zoo/objects_game/util.py\n",
    "\n",
    "sender_inputs, messages, receiver_inputs, receiver_outputs, labels = dump_sender_receiver(game, testloader, True, variable_length=True, device=device)\n",
    "messages = [message.cpu().numpy() for message in messages]\n",
    "for m in messages:\n",
    "  print(str(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GsOHlBuSQ0w-"
   },
   "source": [
    "### Zero-shot evaluation\n",
    "Evaluate the messages on a held out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T10:25:13.241597Z",
     "start_time": "2021-03-14T10:25:13.006598Z"
    },
    "id": "g21i5Du6MxlJ"
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-91639a24e592>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise NotImplementedError"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CLEANED_Template_Signaling_Game--CIFAR-100_implementation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
