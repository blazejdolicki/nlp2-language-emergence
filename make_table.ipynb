{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.0 64-bit ('le-nlp2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "faf78f47fd8955034d4b777123a9000e41db7624cc754dae23eef5d5cda1ecdc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def load_metric_from_event(event_name): \n",
    "    event_path = os.path.join(\"runs\", event_name)\n",
    "    event_name = os.listdir(event_path)[0]\n",
    "    event_path = os.path.join(event_path, event_name)\n",
    "\n",
    "    # only read scalars\n",
    "    ea = event_accumulator.EventAccumulator(event_path, size_guidance={event_accumulator.SCALARS: 0})\n",
    "\n",
    "    # load scalars\n",
    "    ea.Reload()\n",
    "\n",
    "    return get_best_epoch_metric(ea)\n",
    "\n",
    "def get_best_epoch_metrics(ea):\n",
    "    test_accs = ea.Scalars(f\"test/acc\")\n",
    "    test_acc_vals = [metric.value for acc in test_accs]\n",
    "    test_best_acc_idx = np.argmax(test_acc_vals)\n",
    "    test_best_acc = np.max(test_acc_vals)\n",
    "    test_best_epoch = test_accs[test_best_acc_idx].step\n",
    "\n",
    "    train_accs = ea.Scalars(f\"train/acc\")\n",
    "    train_best_acc = train_accs[test_best_acc_idx].value\n",
    "    try:\n",
    "        train_img_clas_accs = ea.Scalars(f\"train/img_clas_acc\")\n",
    "        train_best_img_clas_acc = train_img_clas_accs[test_best_acc_idx].value\n",
    "\n",
    "        \n",
    "        test_img_clas_accs = ea.Scalars(f\"train/img_clas_acc\")\n",
    "        test_best_img_clas_acc = test_img_clas_accs[test_best_acc_idx].value\n",
    "    except KeyError:\n",
    "        train_best_img_clas_acc = np.nan\n",
    "        test_best_img_clas_acc = np.nan\n",
    "    \n",
    "    return [test_best_epoch, train_best_metric, test_best_metric, train_best_img_clas_acc, test_best_img_clas_acc]"
   ]
  },
  {
   "source": [
    "## Define important variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# events in tensorboard\n",
    "events = ['24_03_2021_10_33_16_task_standard_seed_7', '24_03_2021_10_37_04_task_standard_seed_122', '24_03_2021_10_39_50_task_standard_seed_809', '24_03_2021_10_43_50_task_standard_seed_7', '24_03_2021_11_00_48_task_standard_seed_122', '24_03_2021_11_18_26_task_standard_seed_809', '24_03_2021_11_35_57_task_standard_seed_7', '24_03_2021_11_54_58_task_standard_seed_122', '24_03_2021_12_13_03_task_standard_seed_809', '24_03_2021_12_30_12_task_img_clas_seed_7', '24_03_2021_12_37_57_task_img_clas_seed_122', '24_03_2021_12_44_03_task_img_clas_seed_809', '24_03_2021_13_05_47_task_img_clas_seed_7', '24_03_2021_13_27_19_task_img_clas_seed_122', '24_03_2021_13_48_31_task_img_clas_seed_809', '24_03_2021_13_59_50_task_img_clas_seed_7', '24_03_2021_14_21_20_task_img_clas_seed_122', '24_03_2021_14_43_14_task_img_clas_seed_809', '24_03_2021_15_05_02_task_target_clas_seed_7', '24_03_2021_15_09_49_task_target_clas_seed_122', '24_03_2021_15_14_35_task_target_clas_seed_809', '24_03_2021_15_19_17_task_target_clas_seed_7', '24_03_2021_15_41_05_task_target_clas_seed_122', '24_03_2021_16_02_59_task_target_clas_seed_809', '24_03_2021_16_24_57_task_target_clas_seed_7', '24_03_2021_16_47_18_task_target_clas_seed_122', '24_03_2021_17_09_55_task_target_clas_seed_809']\n",
    "\n",
    "# choose which columsn to include\n",
    "include_cols = [\"task\", \"ic_loss_weight\", \"num_imgs\", \"same_class_prob\", \"seed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "args_dir = os.path.join(\"args\")\n",
    "for event_name in events:\n",
    "    # get parameters\n",
    "    with open(f\"{args_dir}\\\\args_{event_name}.json\") as json_file:\n",
    "        params = json.load(json_file)\n",
    "    # wrap each value into a list\n",
    "    params = {key:[value] for key, value in params.items()}\n",
    "\n",
    "    # create dataframe and add parameters\n",
    "    results_df = pd.DataFrame(params)[include_cols]\n",
    "\n",
    "    # add metrics\n",
    "    metric = \"acc\"\n",
    "    metric_cols = [\"best epoch\", f\"best train {metric}\", f\"best test {metric}\"]\n",
    "    results_df.loc[:, metric_cols] = load_metric_from_event(event_name, metric)\n",
    "    # append to final table\n",
    "    results.append(results_df)\n",
    "\n",
    "    metric = \"img_clas_acc\"\n",
    "    metric_cols = [f\"best train {metric}\", f\"best test {metric}\"] # skip best epoch\n",
    "    try:\n",
    "        results_df.loc[:, metric_cols] = load_metric_from_event(event_name, metric)[1:]\n",
    "    except KeyError:\n",
    "        results_df.loc[:, metric_cols] = np.nan\n",
    "    # append to final table\n",
    "    results.append(results_df)\n",
    "\n",
    "results = pd.concat(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          task  same_class_prob  seed  best epoch  best train acc  \\\n",
       "0     standard              0.0     7         NaN         0.96814   \n",
       "0     standard              0.0     7         NaN         0.96814   \n",
       "0     standard              0.0   122         NaN         0.95060   \n",
       "0     standard              0.0   122         NaN         0.95060   \n",
       "0     standard              0.0   809         NaN         0.96734   \n",
       "0     standard              0.0   809         NaN         0.96734   \n",
       "0     standard              0.5     7         NaN         0.94554   \n",
       "0     standard              0.5     7         NaN         0.94554   \n",
       "0     standard              0.5   122         NaN         0.91778   \n",
       "0     standard              0.5   122         NaN         0.91778   \n",
       "0     standard              0.5   809         NaN         0.92722   \n",
       "0     standard              0.5   809         NaN         0.92722   \n",
       "0     standard              1.0     7         NaN         0.90682   \n",
       "0     standard              1.0     7         NaN         0.90682   \n",
       "0     standard              1.0   122         NaN         0.91446   \n",
       "0     standard              1.0   122         NaN         0.91446   \n",
       "0     standard              1.0   809         NaN         0.92762   \n",
       "0     standard              1.0   809         NaN         0.92762   \n",
       "0     img_clas              0.0     7         5.0         0.96110   \n",
       "0     img_clas              0.0     7         5.0         0.96110   \n",
       "0     img_clas              0.0   122         4.0         0.96328   \n",
       "0     img_clas              0.0   122         4.0         0.96328   \n",
       "0     img_clas              0.0   809         5.0         0.93578   \n",
       "0     img_clas              0.0   809         5.0         0.93578   \n",
       "0     img_clas              0.5     7         9.0         0.93624   \n",
       "0     img_clas              0.5     7         9.0         0.93624   \n",
       "0     img_clas              0.5   122         9.0         0.93056   \n",
       "0     img_clas              0.5   122         9.0         0.93056   \n",
       "0     img_clas              0.5   809         5.0         0.95716   \n",
       "0     img_clas              0.5   809         5.0         0.95716   \n",
       "0     img_clas              1.0     7         1.0         0.92506   \n",
       "0     img_clas              1.0     7         1.0         0.92506   \n",
       "0     img_clas              1.0   122         1.0         0.91904   \n",
       "0     img_clas              1.0   122         1.0         0.91904   \n",
       "0     img_clas              1.0   809         1.0         0.91140   \n",
       "0     img_clas              1.0   809         1.0         0.91140   \n",
       "0  target_clas              0.0     7         3.0         0.96978   \n",
       "0  target_clas              0.0     7         3.0         0.96978   \n",
       "0  target_clas              0.0   122         3.0         0.96950   \n",
       "0  target_clas              0.0   122         3.0         0.96950   \n",
       "0  target_clas              0.0   809         3.0         0.97160   \n",
       "0  target_clas              0.0   809         3.0         0.97160   \n",
       "0  target_clas              0.5     7         8.0         0.86184   \n",
       "0  target_clas              0.5     7         8.0         0.86184   \n",
       "0  target_clas              0.5   122         8.0         0.88708   \n",
       "0  target_clas              0.5   122         8.0         0.88708   \n",
       "0  target_clas              0.5   809         5.0         0.88742   \n",
       "0  target_clas              0.5   809         5.0         0.88742   \n",
       "0  target_clas              1.0     7         7.0         0.88434   \n",
       "0  target_clas              1.0     7         7.0         0.88434   \n",
       "0  target_clas              1.0   122         9.0         0.85378   \n",
       "0  target_clas              1.0   122         9.0         0.85378   \n",
       "0  target_clas              1.0   809         7.0         0.84612   \n",
       "0  target_clas              1.0   809         7.0         0.84612   \n",
       "\n",
       "   best test acc  best train img_class_acc  best test img_class_acc  \n",
       "0         0.9756                       NaN                      NaN  \n",
       "0         0.9756                       NaN                      NaN  \n",
       "0         0.9709                       NaN                      NaN  \n",
       "0         0.9709                       NaN                      NaN  \n",
       "0         0.9748                       NaN                      NaN  \n",
       "0         0.9748                       NaN                      NaN  \n",
       "0         0.9609                       NaN                      NaN  \n",
       "0         0.9609                       NaN                      NaN  \n",
       "0         0.9361                       NaN                      NaN  \n",
       "0         0.9361                       NaN                      NaN  \n",
       "0         0.9440                       NaN                      NaN  \n",
       "0         0.9440                       NaN                      NaN  \n",
       "0         0.9408                       NaN                      NaN  \n",
       "0         0.9408                       NaN                      NaN  \n",
       "0         0.9359                       NaN                      NaN  \n",
       "0         0.9359                       NaN                      NaN  \n",
       "0         0.9463                       NaN                      NaN  \n",
       "0         0.9463                       NaN                      NaN  \n",
       "0         0.9707                   0.91821                  0.93550  \n",
       "0         0.9707                   0.91821                  0.93550  \n",
       "0         0.9701                   0.91686                  0.92700  \n",
       "0         0.9701                   0.91686                  0.92700  \n",
       "0         0.9524                   0.89554                  0.91315  \n",
       "0         0.9524                   0.89554                  0.91315  \n",
       "0         0.9574                   0.88198                  0.87095  \n",
       "0         0.9574                   0.88198                  0.87095  \n",
       "0         0.9434                   0.88221                  0.86570  \n",
       "0         0.9434                   0.88221                  0.86570  \n",
       "0         0.9733                   0.89384                  0.87845  \n",
       "0         0.9733                   0.89384                  0.87845  \n",
       "0         0.9381                   0.99894                  1.00000  \n",
       "0         0.9381                   0.99894                  1.00000  \n",
       "0         0.9398                   0.99997                  1.00000  \n",
       "0         0.9398                   0.99997                  1.00000  \n",
       "0         0.9342                   0.99976                  1.00000  \n",
       "0         0.9342                   0.99976                  1.00000  \n",
       "0         0.9743                   0.33506                  0.32790  \n",
       "0         0.9743                   0.33506                  0.32790  \n",
       "0         0.9762                   0.32850                  0.32440  \n",
       "0         0.9762                   0.32850                  0.32440  \n",
       "0         0.9758                   0.35434                  0.37010  \n",
       "0         0.9758                   0.35434                  0.37010  \n",
       "0         0.9094                   0.43562                  0.35360  \n",
       "0         0.9094                   0.43562                  0.35360  \n",
       "0         0.9246                   0.55590                  0.45860  \n",
       "0         0.9246                   0.55590                  0.45860  \n",
       "0         0.9237                   0.55706                  0.42140  \n",
       "0         0.9237                   0.55706                  0.42140  \n",
       "0         0.9264                   0.62112                  0.47670  \n",
       "0         0.9264                   0.62112                  0.47670  \n",
       "0         0.9169                   0.48258                  0.40810  \n",
       "0         0.9169                   0.48258                  0.40810  \n",
       "0         0.9079                   0.49200                  0.41180  \n",
       "0         0.9079                   0.49200                  0.41180  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>task</th>\n      <th>same_class_prob</th>\n      <th>seed</th>\n      <th>best epoch</th>\n      <th>best train acc</th>\n      <th>best test acc</th>\n      <th>best train img_class_acc</th>\n      <th>best test img_class_acc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>standard</td>\n      <td>0.0</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>0.96814</td>\n      <td>0.9756</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>standard</td>\n      <td>0.0</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>0.96814</td>\n      <td>0.9756</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>standard</td>\n      <td>0.0</td>\n      <td>122</td>\n      <td>NaN</td>\n      <td>0.95060</td>\n      <td>0.9709</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>standard</td>\n      <td>0.0</td>\n      <td>122</td>\n      <td>NaN</td>\n      <td>0.95060</td>\n      <td>0.9709</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>standard</td>\n      <td>0.0</td>\n      <td>809</td>\n      <td>NaN</td>\n      <td>0.96734</td>\n      <td>0.9748</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>standard</td>\n      <td>0.0</td>\n      <td>809</td>\n      <td>NaN</td>\n      <td>0.96734</td>\n      <td>0.9748</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>standard</td>\n      <td>0.5</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>0.94554</td>\n      <td>0.9609</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>standard</td>\n      <td>0.5</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>0.94554</td>\n      <td>0.9609</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>standard</td>\n      <td>0.5</td>\n      <td>122</td>\n      <td>NaN</td>\n      <td>0.91778</td>\n      <td>0.9361</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>standard</td>\n      <td>0.5</td>\n      <td>122</td>\n      <td>NaN</td>\n      <td>0.91778</td>\n      <td>0.9361</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>standard</td>\n      <td>0.5</td>\n      <td>809</td>\n      <td>NaN</td>\n      <td>0.92722</td>\n      <td>0.9440</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>standard</td>\n      <td>0.5</td>\n      <td>809</td>\n      <td>NaN</td>\n      <td>0.92722</td>\n      <td>0.9440</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>standard</td>\n      <td>1.0</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>0.90682</td>\n      <td>0.9408</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>standard</td>\n      <td>1.0</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>0.90682</td>\n      <td>0.9408</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>standard</td>\n      <td>1.0</td>\n      <td>122</td>\n      <td>NaN</td>\n      <td>0.91446</td>\n      <td>0.9359</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>standard</td>\n      <td>1.0</td>\n      <td>122</td>\n      <td>NaN</td>\n      <td>0.91446</td>\n      <td>0.9359</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>standard</td>\n      <td>1.0</td>\n      <td>809</td>\n      <td>NaN</td>\n      <td>0.92762</td>\n      <td>0.9463</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>standard</td>\n      <td>1.0</td>\n      <td>809</td>\n      <td>NaN</td>\n      <td>0.92762</td>\n      <td>0.9463</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>img_clas</td>\n      <td>0.0</td>\n      <td>7</td>\n      <td>5.0</td>\n      <td>0.96110</td>\n      <td>0.9707</td>\n      <td>0.91821</td>\n      <td>0.93550</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>img_clas</td>\n      <td>0.0</td>\n      <td>7</td>\n      <td>5.0</td>\n      <td>0.96110</td>\n      <td>0.9707</td>\n      <td>0.91821</td>\n      <td>0.93550</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>img_clas</td>\n      <td>0.0</td>\n      <td>122</td>\n      <td>4.0</td>\n      <td>0.96328</td>\n      <td>0.9701</td>\n      <td>0.91686</td>\n      <td>0.92700</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>img_clas</td>\n      <td>0.0</td>\n      <td>122</td>\n      <td>4.0</td>\n      <td>0.96328</td>\n      <td>0.9701</td>\n      <td>0.91686</td>\n      <td>0.92700</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>img_clas</td>\n      <td>0.0</td>\n      <td>809</td>\n      <td>5.0</td>\n      <td>0.93578</td>\n      <td>0.9524</td>\n      <td>0.89554</td>\n      <td>0.91315</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>img_clas</td>\n      <td>0.0</td>\n      <td>809</td>\n      <td>5.0</td>\n      <td>0.93578</td>\n      <td>0.9524</td>\n      <td>0.89554</td>\n      <td>0.91315</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>img_clas</td>\n      <td>0.5</td>\n      <td>7</td>\n      <td>9.0</td>\n      <td>0.93624</td>\n      <td>0.9574</td>\n      <td>0.88198</td>\n      <td>0.87095</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>img_clas</td>\n      <td>0.5</td>\n      <td>7</td>\n      <td>9.0</td>\n      <td>0.93624</td>\n      <td>0.9574</td>\n      <td>0.88198</td>\n      <td>0.87095</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>img_clas</td>\n      <td>0.5</td>\n      <td>122</td>\n      <td>9.0</td>\n      <td>0.93056</td>\n      <td>0.9434</td>\n      <td>0.88221</td>\n      <td>0.86570</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>img_clas</td>\n      <td>0.5</td>\n      <td>122</td>\n      <td>9.0</td>\n      <td>0.93056</td>\n      <td>0.9434</td>\n      <td>0.88221</td>\n      <td>0.86570</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>img_clas</td>\n      <td>0.5</td>\n      <td>809</td>\n      <td>5.0</td>\n      <td>0.95716</td>\n      <td>0.9733</td>\n      <td>0.89384</td>\n      <td>0.87845</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>img_clas</td>\n      <td>0.5</td>\n      <td>809</td>\n      <td>5.0</td>\n      <td>0.95716</td>\n      <td>0.9733</td>\n      <td>0.89384</td>\n      <td>0.87845</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>img_clas</td>\n      <td>1.0</td>\n      <td>7</td>\n      <td>1.0</td>\n      <td>0.92506</td>\n      <td>0.9381</td>\n      <td>0.99894</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>img_clas</td>\n      <td>1.0</td>\n      <td>7</td>\n      <td>1.0</td>\n      <td>0.92506</td>\n      <td>0.9381</td>\n      <td>0.99894</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>img_clas</td>\n      <td>1.0</td>\n      <td>122</td>\n      <td>1.0</td>\n      <td>0.91904</td>\n      <td>0.9398</td>\n      <td>0.99997</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>img_clas</td>\n      <td>1.0</td>\n      <td>122</td>\n      <td>1.0</td>\n      <td>0.91904</td>\n      <td>0.9398</td>\n      <td>0.99997</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>img_clas</td>\n      <td>1.0</td>\n      <td>809</td>\n      <td>1.0</td>\n      <td>0.91140</td>\n      <td>0.9342</td>\n      <td>0.99976</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>img_clas</td>\n      <td>1.0</td>\n      <td>809</td>\n      <td>1.0</td>\n      <td>0.91140</td>\n      <td>0.9342</td>\n      <td>0.99976</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>target_clas</td>\n      <td>0.0</td>\n      <td>7</td>\n      <td>3.0</td>\n      <td>0.96978</td>\n      <td>0.9743</td>\n      <td>0.33506</td>\n      <td>0.32790</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>target_clas</td>\n      <td>0.0</td>\n      <td>7</td>\n      <td>3.0</td>\n      <td>0.96978</td>\n      <td>0.9743</td>\n      <td>0.33506</td>\n      <td>0.32790</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>target_clas</td>\n      <td>0.0</td>\n      <td>122</td>\n      <td>3.0</td>\n      <td>0.96950</td>\n      <td>0.9762</td>\n      <td>0.32850</td>\n      <td>0.32440</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>target_clas</td>\n      <td>0.0</td>\n      <td>122</td>\n      <td>3.0</td>\n      <td>0.96950</td>\n      <td>0.9762</td>\n      <td>0.32850</td>\n      <td>0.32440</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>target_clas</td>\n      <td>0.0</td>\n      <td>809</td>\n      <td>3.0</td>\n      <td>0.97160</td>\n      <td>0.9758</td>\n      <td>0.35434</td>\n      <td>0.37010</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>target_clas</td>\n      <td>0.0</td>\n      <td>809</td>\n      <td>3.0</td>\n      <td>0.97160</td>\n      <td>0.9758</td>\n      <td>0.35434</td>\n      <td>0.37010</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>target_clas</td>\n      <td>0.5</td>\n      <td>7</td>\n      <td>8.0</td>\n      <td>0.86184</td>\n      <td>0.9094</td>\n      <td>0.43562</td>\n      <td>0.35360</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>target_clas</td>\n      <td>0.5</td>\n      <td>7</td>\n      <td>8.0</td>\n      <td>0.86184</td>\n      <td>0.9094</td>\n      <td>0.43562</td>\n      <td>0.35360</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>target_clas</td>\n      <td>0.5</td>\n      <td>122</td>\n      <td>8.0</td>\n      <td>0.88708</td>\n      <td>0.9246</td>\n      <td>0.55590</td>\n      <td>0.45860</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>target_clas</td>\n      <td>0.5</td>\n      <td>122</td>\n      <td>8.0</td>\n      <td>0.88708</td>\n      <td>0.9246</td>\n      <td>0.55590</td>\n      <td>0.45860</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>target_clas</td>\n      <td>0.5</td>\n      <td>809</td>\n      <td>5.0</td>\n      <td>0.88742</td>\n      <td>0.9237</td>\n      <td>0.55706</td>\n      <td>0.42140</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>target_clas</td>\n      <td>0.5</td>\n      <td>809</td>\n      <td>5.0</td>\n      <td>0.88742</td>\n      <td>0.9237</td>\n      <td>0.55706</td>\n      <td>0.42140</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>target_clas</td>\n      <td>1.0</td>\n      <td>7</td>\n      <td>7.0</td>\n      <td>0.88434</td>\n      <td>0.9264</td>\n      <td>0.62112</td>\n      <td>0.47670</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>target_clas</td>\n      <td>1.0</td>\n      <td>7</td>\n      <td>7.0</td>\n      <td>0.88434</td>\n      <td>0.9264</td>\n      <td>0.62112</td>\n      <td>0.47670</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>target_clas</td>\n      <td>1.0</td>\n      <td>122</td>\n      <td>9.0</td>\n      <td>0.85378</td>\n      <td>0.9169</td>\n      <td>0.48258</td>\n      <td>0.40810</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>target_clas</td>\n      <td>1.0</td>\n      <td>122</td>\n      <td>9.0</td>\n      <td>0.85378</td>\n      <td>0.9169</td>\n      <td>0.48258</td>\n      <td>0.40810</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>target_clas</td>\n      <td>1.0</td>\n      <td>809</td>\n      <td>7.0</td>\n      <td>0.84612</td>\n      <td>0.9079</td>\n      <td>0.49200</td>\n      <td>0.41180</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>target_clas</td>\n      <td>1.0</td>\n      <td>809</td>\n      <td>7.0</td>\n      <td>0.84612</td>\n      <td>0.9079</td>\n      <td>0.49200</td>\n      <td>0.41180</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "results.drop([\"ic_loss_weight\", \"num_imgs\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}